# LangChain-Chat-LLM-Embedded_models

# LangChain Core Components - Practice

This repository contains my practice code and experiments with **LangChain core components** including LLMs, ChatModels, Messages, Embeddings, and Conversational Chatbots.  
The goal is to gain hands-on experience in building blocks of LLM-powered applications.

##  Topics Covered

###  LLM Models
- Using `LLM` wrappers with OpenAI and HuggingFace models.
- Prompt engineering basics.

###  Chat Models
- Working with `ChatOpenAI` and other chat model wrappers.
- Handling chat-specific inputs and outputs.

###  Messages
- Understanding `SystemMessage`, `HumanMessage`, and `AIMessage`.
- Building multi-turn conversations.

###  Embeddings
- Generating embeddings using `OpenAIEmbeddings` and other providers.
- Storing and searching embeddings with FAISS/Chroma.

###  Conversational Chatbot
- Building a chatbot with memory (conversation buffer).
- Retrieval-Augmented Generation (RAG) basics.
- Multi-turn Q&A.


LangChain-Core-Practice

##  Project Structure

1 llms
--llm_openai_demo.py
-- llm_huggingface_demo.py

2.chat_models
-- chat_openai_demo.py
-- multi_turn_chat_demo.py

3.messages
-- system_message_demo.py
-- human_message_demo.py
-- ai_message_demo.py

4.Embeddings
-- embeddings_openai_demo.py
-- embeddings_search_faiss.py
-- embeddings_chroma_demo.py

5.Chatbot
-- conversational_chatbot.py

6.requirements.txt

7.README.md
